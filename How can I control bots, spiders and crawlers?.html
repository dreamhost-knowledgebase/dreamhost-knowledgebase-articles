<h2>Overview</h2>
<div class="solvvy-solution">
<p>Bots, spiders, and other crawlers hitting your dynamic pages can cause extensive resource (memory and CPU) usage. This can lead to high load on the server and slow down your site(s).</p>
<p>One option to reduce server load from bots, spiders, and other crawlers is to create a <span class="text-object">robots.txt</span> file at the root of your website. This tells search engines what content on your site they should and should not index. This can be helpful, for example, if you want to keep a portion of your site out of the Google search engine index.</p>
<p>If you prefer not to create this file yourself, you can have DreamHost create one for you automatically (on a per-domain basis) on the <a class="panel-link" href="https://panel.dreamhost.com/index.cgi?tree=advanced.robots&amp;" target="_blank" rel="noopener">Block Spiders</a> page.</p>
<div class="alert alert-note">
<div class="alert-icon"><img src="https://kbimages.dreamhosters.com/images/dh-kb-note-icon.svg" alt="" width="60" height="60" /></div>
<div class="alert-content">
<p>While most of the major search engines respect <span class="text-object">robots.txt</span> directives, this file only acts as a <em>suggestion</em> to compliant search engines and does not <em>prevent</em> search engines (or other similar tools, such as email/content scrapers) from accessing the content or making it available.</p>
</div>
</div>
</div>
<h2><span id="Blocking_robots">Blocking robots</span></h2>
<div class="solvvy-solution">
<p>The problem may be that Google, Yahoo, or another search engine bot is over-browsing your site. (This is the sort of problem that feeds on itself; if the bot is not able to complete its search because of a lack of resources, it may launch the same search over and over again.)</p>
</div>
<h2><span id="Blocking_Googlebots">Blocking Googlebots</span></h2>
<div class="solvvy-solution">
<p>In the following example, the IP of 66.249.66.167 was found in your <a href="https://help.dreamhost.com/hc/en-us/articles/216512197-Viewing-your-access-and-error-logs-via-SFTP">access.log</a>. You can check which company this IP belongs to by running the ‘host’ command via <a href="https://help.dreamhost.com/hc/en-us/articles/216041267-SSH-overview">SSH</a>:</p>
<div class="preboxcontainer">
<pre class="prebox"><span class="server">[server]$ </span><span class="command">host 66.249.66.167</span>
<span class="cmdoutput">167.66.249.66.in-addr.arpa domain name pointer crawl-66-249-66-167.googlebot.com.</span>
</pre>
</div>
<p>To block this Googlebot, use the following in your <span class="text-object">robots.txt</span> file:</p>
<div class="preboxcontainer">
<pre class="prebox"># go away Googlebot
User-agent: Googlebot
Disallow: /</pre>
</div>
<dl>
<dt>
<h3>Explanation of the fields above:</h3>
</dt>
</dl>
<dl>
<dt><strong># go away</strong></dt>
<dd>This is a comment which is only used so you know why you created this rule.</dd>
<dt><strong>User-agent</strong></dt>
<dd>The name of the bot to which the next rule will apply.</dd>
<dt><strong>Disallow</strong></dt>
<dd>The path of the URL you wish to block. This forward slash means the entire site will be blocked.</dd>
</dl>
<p>View further information about Google robots by clicking the following:</p>
<ul>
<li><a href="https://support.google.com/webmasters/answer/6062608?hl=en">Google robots.txt</a></li>
</ul>
</div>
<h2><span id="Blocking_Yahoo">Blocking Yahoo</span></h2>
<div class="solvvy-solution">
<p>Yahoo's crawling bots comply to the <span class="code">crawl-delay</span> rule in <span class="text-object">robots.txt</span> which limits their fetching activity. For example, to tell Yahoo not to fetch a page more than once every 10 seconds, you would add the following:</p>
<div class="preboxcontainer">
<pre class="prebox"># slow down Yahoo
User-agent: Slurp
Crawl-delay: 10</pre>
</div>
<dl>
<dt>
<h3>Explanation of the fields above:</h3>
</dt>
</dl>
<dl>
<dt><strong># slow down Yahoo</strong></dt>
<dd>This is a comment which is only used so you know why you created this rule.</dd>
<dt><strong>User-agent: Slurp</strong></dt>
<dd>Slurp is the Yahoo User-agent name. You must use this to block Yahoo.</dd>
<dt><strong>Crawl-delay</strong></dt>
<dd>Tells the User-agent to wait 10 seconds between each request to the server.</dd>
</dl>
<p>View further information about Yahoo robots by clicking the following:</p>
<ul>
<li><a href="https://help.yahoo.com/kb/search/slurp-crawling-page-sln22600.html">Yahoo robots.txt</a></li>
</ul>
</div>
<h2><span id="Slowing_good_bots">Slowing good bots</span></h2>
<div class="solvvy-solution">
<p>Use the following to slow some, but not all, good bots:</p>
<div class="preboxcontainer">
<pre class="prebox">User-agent: * <br />Crawl-Delay: 10</pre>
</div>
<dl>
<dt>
<h3>Explanation of the fields above:</h3>
</dt>
</dl>
<dl>
<dt><strong>User-agent: *</strong></dt>
<dd>Applies to all User-agents.</dd>
<dt><strong>Crawl-delay</strong></dt>
<dd>Tells the User-agent to wait 10 seconds between each request to the server.</dd>
</dl>
<div class="alert alert-note">
<div class="alert-icon"><img src="https://kbimages.dreamhosters.com/images/dh-kb-note-icon.svg" alt="" width="60" height="60" /></div>
<div class="alert-content">
<p><strong>Google Bots</strong></p>
<ul>
<li>Googlebot ignores the crawl-delay directive.</li>
<li>To slow down Googlebot, you’ll need to sign up at <a href="http://www.google.com/webmasters/tools" target="_self">Google Search Console</a>.</li>
<li>Once your account is created, you can <a href="https://support.google.com/webmasters/answer/48620?hl=en" target="_blank" rel="noopener">set the crawl rate</a>&nbsp;in their panel.</li>
</ul>
</div>
</div>
</div>
<h2><span id="Blocking_all_bots">Blocking all bots</span></h2>
<div class="solvvy-solution">
<p>To disallow all bots:</p>
<div class="preboxcontainer">
<pre class="prebox">User-agent: *
Disallow: /</pre>
</div>
<p>To disallow them on a specific folder:</p>
<div class="preboxcontainer">
<pre class="prebox">User-agent: *
Disallow: /<span class="code-highlight">yourfolder</span>/</pre>
</div>
<dl>
<dd></dd>
<dd></dd>
</dl>
<div class="alert alert-important">
<div class="alert-icon"><img src="https://kbimages.dreamhosters.com/images/dh-kb-important-icon.svg" alt="" width="60" height="60" /></div>
<div class="alert-content">
<p>Bad bots may use this content as a list of targets.</p>
</div>
</div>
<dl>
<dt>
<h3>Explanation of the fields above:</h3>
</dt>
</dl>
<dl>
<dt><strong>User-agent: *</strong></dt>
<dd>Applies to all User-agents.</dd>
<dt><strong>Disallow: /</strong></dt>
<dd>Disallows the indexing of everything.</dd>
<dt><strong>Disallow: /yourfolder/</strong></dt>
<dd>Disallows the indexing of this single folder.</dd>
</dl>
</div>
<h2><span id="Use_caution">Use caution</span></h2>
<div class="solvvy-solution">
<p>Blocking all bots (User-agent: *) from your entire site (Disallow: /) will get your site de-indexed from legitimate search engines. Also, note that bad bots will likely ignore your <span class="text-object">robots.txt</span> file, so you may want to block their user-agent with an <a href="/hc/en-us/articles/216456227--htaccess-overview">.htaccess file</a>.</p>
<p>Bad bots may use your <span class="text-object">robots.txt</span> file as a target list, so you may want to skip listing directories in the <span class="text-object">robots.txt</span> file. Bad bots may also use false or misleading User-agents, so blocking User-agents with .htaccess may not work as well as anticipated.</p>
<p>If you don't want to block anyone, this is a good default <span class="text-object">robots.txt</span> file:</p>
<div class="preboxcontainer">
<pre class="prebox">User-agent: *
Disallow:</pre>
</div>
<p>You may need to remove <span class="text-object">robots.txt</span> in this case, if you don't mind 404 requests in your logs.</p>
<p>DreamHost recommends that you only block specific User-agents and files/directories, rather than *, unless you're 100% sure that's what you want.</p>
</div>
<h2><span id="Blocking_bad_referrers">Blocking bad referrers</span></h2>
<div class="solvvy-solution">
<p>For detailed instructions, please visit the article on how to <a href="/hc/en-us/articles/216363197-How-do-I-prevent-image-hotlinking-">block referrers</a>.</p>
</div>
<h2>See also</h2>
<div class="solvvy-hidden">
<ul>
<li><a href="/hc/en-us/articles/216041267-SSH-overview">SSH overview</a></li>
<li><a href="/hc/en-us/articles/216456227--htaccess-overview">.htaccess overview</a></li>
<li><a href="https://help.dreamhost.com/hc/en-us/articles/216512197-Viewing-your-access-and-error-logs-via-SFTP">Viewing your access and error log via SFTP</a></li>
<li><a href="https://help.dreamhost.com/hc/en-us/articles/216105097-Viewing-and-examining-your-access-log-via-SSH">Viewing and examining your access log via SSH</a></li>
</ul>
</div>
